---
name: nm-memory-evolution
description: |
  Evidence-based brain optimization. Analyzes usage patterns to consolidate
  fragmented memories, enrich sparse ones, prune stale/irrelevant ones,
  and normalize tags. Improves recall quality over time.
metadata:
  stage: workflow
  version: "1.0"
  requires: neural-memory (pip install neural-memory)
  tags: [memory, evolution, optimize, prune, consolidate]
agent: Memory Evolution Strategist
trigger:
  commands: ["/memory-evolution", "/nm-evolve"]
  keywords: ["optimize brain", "clean memory", "prune", "consolidate memories"]
allowed-tools:
  - nmem_remember
  - nmem_recall
  - nmem_stats
  - nmem_context
  - nmem_auto
---

# NM Memory Evolution â€” Memory Evolution Strategist

> Evidence-based brain optimization using actual usage patterns.
> Consolidates, enriches, prunes, and normalizes â€” making recall more precise over time.

## Trigger

```
/memory-evolution                          # Full brain optimization
/memory-evolution "focus on auth topic"    # Scoped to topic
/nm-evolve "prune expired todos"           # Specific operation
```

---

## Analysis Phase

Before any changes, generate evolution opportunities:

```python
# 1. Usage patterns
stats = nmem_stats()
# â†’ recall_frequency, activation_scores, orphan_neurons

# 2. Cluster detection  
context = nmem_context(topic=focus_area)
# â†’ related memory clusters, fragmentation patterns

# 3. Tag analysis
# â†’ inconsistency, synonyms, normalization needs
```

---

## 4 Evolution Operations

### 1. Consolidation
**When:** Multiple fragmented memories cover same concept

**Example:**
```
Before (3 memories):
  [fact] "API uses JWT"
  [fact] "JWT tokens expire in 24h"
  [fact] "JWT stored in Authorization header"

After (1 memory):
  [instruction] "API auth: JWT tokens, 24h expiry, sent via Authorization header. 
                 Chosen for stateless architecture (see decision #42)."
```

**Rules:**
- Show before/after preview â€” never auto-consolidate
- Keep highest priority + merge all tags
- Create `SUPERSEDES` synapse to old memories
- Log: "Consolidated 3 â†’ 1 [topic]"

### 2. Enrichment
**When:** Memories exist but lack context/reasoning

**Example:**
```
Before: [decision] "Using Redis for cache"
After:  [decision] "Using Redis for cache. Reason: Redis Cluster supports Lua scripts 
                   needed for atomic counter ops. Team has Redis expertise. 
                   Chosen over Memcached on 2026-01-15."
```

**Sources for enrichment:**
- Related memories in the activation cluster
- User can be asked for missing info (non-blocking)

### 3. Pruning
**When:** Memories that reduce recall quality

**Prune candidates:**
- Expired TTL memories (todos past deadline, stale context)
- Duplicate/near-duplicate memories (similarity > 0.95)
- Orphaned facts with 0 recall in 60d
- Superseded decisions (overridden by newer ones)
- Out-of-scope memories (wrong project/context)

**Rules:**
- NEVER hard-delete â€” archive with `status=archived`
- Show full prune list before executing
- "Archived X memories" â€” not "deleted"
- Allow rescue: user can un-archive any item

### 4. Tag Normalization
**When:** Inconsistent tags reduce recall precision

**Common issues:**
- Synonyms: "frontend" / "front-end" / "FE" â†’ normalize to "frontend"
- Abbreviations: "db" / "database" / "DB" â†’ normalize to "database"  
- Case: "Auth" / "auth" / "AUTH" â†’ normalize to "auth"
- Language mix: "xÃ¡c thá»±c" / "auth" for same concept â†’ pick one

**Process:**
1. Build tag frequency map
2. Identify synonym clusters
3. Propose normalization mapping
4. Apply after user confirms

---

## Output Format

```
ðŸ”„ Memory Evolution Plan
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ðŸ“Š Analysis Results
  Memories analyzed: 127
  Evolution opportunities: 23

ðŸ“‹ Proposed Operations

CONSOLIDATE (4 groups â†’ 4 memories)
  1. Auth memories: 5 fragments â†’ 1 instruction [preview]
  2. Database facts: 3 fragments â†’ 1 fact [preview]
  ...

ENRICH (6 memories lacking context)
  1. [decision] "Using Redis" â€” missing reasoning [add]
  2. [instruction] "Always validate input" â€” missing scope [add]
  ...

PRUNE (9 memories)
  1. 4 expired todos (past deadline) [archive]
  2. 3 orphaned facts (0 recall in 60d) [archive]
  3. 2 near-duplicates [merge]

NORMALIZE TAGS
  "frontend" / "front-end" / "FE" â†’ "frontend" (affects 18 memories)
  "db" / "database" â†’ "database" (affects 12 memories)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Execute plan? [all / select / cancel]
  > all        â†’ execute all operations
  > select     â†’ choose operations individually
  > cancel     â†’ abort
```

---

## Execution Protocol

1. **Show full plan** â€” never execute without preview
2. **Execute in order:** Prune â†’ Consolidate â†’ Enrich â†’ Normalize
   (pruning first reduces noise for better consolidation)
3. **Checkpoint after each phase** â€” can stop mid-way
4. **Create evolution snapshot** before starting (rollback point)

---

## Post-Evolution Report

```
âœ… Evolution Complete

  Consolidated: 4 memory groups (15 â†’ 4)
  Enriched: 6 memories
  Archived: 9 memories
  Tags normalised: 30 memories updated

  Brain quality: B- â†’ A- (estimated)
  
ðŸ’¡ Recommended audit in 7 days: /memory-audit
```

---

## Rules

- **Never auto-prune** â€” always show prune list to user
- **Archive, don't delete** â€” memories may be relevant later
- **Preserve intent** â€” consolidation must not lose meaning
- **Test recall after** â€” spot-check key topics after evolution
- **Vietnamese support** â€” operations work regardless of language
